{"cells":[{"cell_type":"code","source":["### If you have the files on Google Drive\n","# We recommend using Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS4s7BpTdiLC","executionInfo":{"status":"ok","timestamp":1658010398037,"user_tz":420,"elapsed":1093,"user":{"displayName":"Arno Hartholt","userId":"05902089586467377630"}},"outputId":"3ca7d5f5-f09f-48a0-c42a-49a6758f79aa"},"id":"yS4s7BpTdiLC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["### Change the path to point to the source directory\n","# %cd /YOUR_PATH/src\n","%cd ./src"],"metadata":{"id":"MtT3lb2peL00","executionInfo":{"status":"ok","timestamp":1658010398038,"user_tz":420,"elapsed":5,"user":{"displayName":"Arno Hartholt","userId":"05902089586467377630"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"78f5dc8a-59e4-4634-9484-f34547ee5df5"},"id":"MtT3lb2peL00","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1VwEes_n1K_s8MWto1dlkl_2daHsitkQi/Fidelity/src\n"]}]},{"cell_type":"code","source":["### Check that you are in the correct working directory\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDoNXlp60kpi","executionInfo":{"status":"ok","timestamp":1658010398234,"user_tz":420,"elapsed":200,"user":{"displayName":"Arno Hartholt","userId":"05902089586467377630"}},"outputId":"01eda9fb-32a8-41f8-dc22-aa6bd25303af"},"id":"aDoNXlp60kpi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1VwEes_n1K_s8MWto1dlkl_2daHsitkQi/Fidelity/src\n"]}]},{"cell_type":"code","execution_count":null,"id":"2975db20","metadata":{"id":"2975db20","colab":{"base_uri":"https://localhost:8080/","height":330},"executionInfo":{"status":"error","timestamp":1658010398725,"user_tz":420,"elapsed":499,"user":{"displayName":"Arno Hartholt","userId":"05902089586467377630"}},"outputId":"4464820c-883a-4a0a-e23c-498a175ce93b"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-24361ee839b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Call the make_json function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mmake_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsonFilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-18-24361ee839b2>\u001b[0m in \u001b[0;36mmake_json\u001b[0;34m(csvFilePath, jsonFilePath)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Open a csv reader called DictReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8-sig'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mcsvReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/vhfc_vh_cluster_data_N32934.csv'"]}],"source":["### STEP 1 - Convert CSV to JSON\n","import csv\n","import json\n","\n","\n","# Function to convert a CSV to JSON\n","# Takes the file paths as arguments\n","def make_json(csvFilePath, jsonFilePath):\n","     \n","    # create a dictionary\n","    data = {}\n","     \n","    # Open a csv reader called DictReader\n","    with open(csvFilePath, encoding='utf-8-sig') as csvf:\n","        csvReader = csv.DictReader(csvf)\n","         \n","        # Convert each row into a dictionary\n","        # and add it to data\n","        for rows in csvReader:\n","             \n","            # Assuming a column named 'PaperID' to\n","            # be the primary key -> Double check in the csv file that you load\n","            key = rows['PaperID']\n","            data[key] = rows\n"," \n","    # Open a json writer, and use the json.dumps()\n","    # function to dump data\n","    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf:\n","        jsonf.write(json.dumps(data, indent=4))\n","\n","        \n","# Decide the two file paths according to your\n","# computer system\n","# WARNING: Make sure these files exist and are pointing to the right location\n","csvFilePath = r'../data/vhfc_vh_cluster_data_N32934.csv'\n","jsonFilePath = r'../data/vh_fidelity.json'\n"," \n","# Call the make_json function\n","make_json(csvFilePath, jsonFilePath)"]},{"cell_type":"code","source":["# Install dependencies\n","!pip install transformers"],"metadata":{"id":"mMxz3CYb3_zh"},"id":"mMxz3CYb3_zh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install plotly"],"metadata":{"id":"jz7kzgeSTgNU"},"id":"jz7kzgeSTgNU","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install plotly-express"],"metadata":{"id":"4f4g_LJ102ww"},"id":"4f4g_LJ102ww","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install pyyaml==5.4.1"],"metadata":{"id":"qiJ9GLnY1LLQ"},"id":"qiJ9GLnY1LLQ","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"1e910215","metadata":{"id":"1e910215"},"outputs":[],"source":["# check if GPU/CUDA is available\n","# WARNING: Under the current setup a GPU is required! Please make sure that you have access to one.\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"id":"dadda43b","metadata":{"id":"dadda43b"},"outputs":[],"source":["### STEP 2 - Get the SPECTER Embeddings\n","# Run in terminal to get embeddings\n","!CUDA_VISIBLE_DEVICES=0 python ./embed_papers_hf.py --data-path ../data/vh_fidelity.json --output ../data/vh_fidelity_embeddings.json"]},{"cell_type":"code","execution_count":null,"id":"a6e79396","metadata":{"id":"a6e79396"},"outputs":[],"source":["### STEP 3 - Import the data to pandas dataframe\n","import pandas as pd\n","\n","# Specter embeddings\n","df_embeddings = pd.read_json(r'../data/vh_fidelity_embeddings.json', lines=True)\n","\n","# Meta data\n","df_meta_data = pd.read_json(r'../data/vh_fidelity.json', orient='records').T\n","df_meta_data = df_meta_data.set_index('PaperID')\n","df_meta_data.index = df_meta_data.index.astype('int64')\n","\n","# prep the embeddings to be merged with meta data\n","df_embeddings_list = pd.DataFrame(df_embeddings.embedding.tolist())\n","df_embeddings = pd.concat([df_embeddings.Key, df_embeddings_list], axis=1)\n","df_embeddings = df_embeddings.set_index('Key')"]},{"cell_type":"code","source":["# check that everything looks good\n","df_embeddings\n"],"metadata":{"id":"RPQvNeVh9l9a"},"id":"RPQvNeVh9l9a","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"b8c983bc","metadata":{"id":"b8c983bc"},"outputs":[],"source":["### STEP 4 - Combine the meta data and embeddings\n","df_data = pd.concat([df_meta_data, df_embeddings], axis=1, join='inner')\n","df_data"]},{"cell_type":"code","execution_count":null,"id":"47a05f2b","metadata":{"id":"47a05f2b"},"outputs":[],"source":["### STEP 5 - Get the tSNE 2d projections\n","from sklearn.manifold import TSNE\n","\n","skip_factor = 1\n","features = df_embeddings.iloc[::skip_factor, :]\n","tsne = TSNE(n_components=2, random_state=0)\n","projections = tsne.fit_transform(features)\n","df_projections = pd.DataFrame({'tSNE1': projections[:, 0], 'tSNE2': projections[:, 1]})\n","df_projections_meta = df_data.iloc[::skip_factor, :]\n","df_projections_meta = df_projections_meta.reset_index()\n","df_embeddings_proj = pd.concat([df_projections_meta, df_projections], axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"8ca66f90","metadata":{"id":"8ca66f90"},"outputs":[],"source":["### STEP 6 - Save the TSNE projections + rest of data\n","df_embeddings_proj.to_csv(r'../data/fidelity_tsne.csv')"]},{"cell_type":"code","source":["# Load the data to skip the initial steps if interested in alternative clustering and analysis methods\n","# df_embeddings_proj= pd.read_csv(r'../data/fidelity_tsne.csv')"],"metadata":{"id":"G0I3EmIA1wjq"},"id":"G0I3EmIA1wjq","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check everything looks good\n","df_embeddings_proj"],"metadata":{"id":"OtN2j91xT5Bp"},"id":"OtN2j91xT5Bp","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"788ad071","metadata":{"id":"788ad071"},"outputs":[],"source":["### STEP 7 - Visualize and Save\n","import numpy as np\n","import plotly.express as px\n","\n","# remove empty records\n","df_embeddings_proj[\"Title\"].replace('', np.nan, inplace=True)\n","df_embeddings_proj.dropna(subset=[\"Title\"], inplace=True)\n","\n","fig = px.scatter(\n","    df_embeddings_proj, x='tSNE1', y='tSNE2', \n","    color = \"Published Year\", hover_data = ['Title']\n",")\n","fig.show()\n","# save interactive website\n","fig.write_html(\"../data/fidelity_data_visualization.html\")"]},{"cell_type":"code","execution_count":null,"id":"d0e5ce64","metadata":{"id":"d0e5ce64"},"outputs":[],"source":["### STEP 8 - Identify the optimal k for k-means clustering\n","# Import kMeans\n","from sklearn.cluster import KMeans\n","# Import ElbowVisualizer\n","from yellowbrick.cluster import KElbowVisualizer\n","\n","np.random.seed(0)\n","\n","model = KMeans()\n","# Make sure that this is the right index where the embeddings start in df_embeddings_proj -> Look for column with label '0'\n","embedding_start_idx = 13\n","# k is range of number of clusters.\n","visualizer = KElbowVisualizer(model, k=(2,100), timings= True)\n","df_elbow = df_embeddings_proj.iloc[:, embedding_start_idx:embedding_start_idx+768]\n","visualizer.fit(df_elbow.astype('float'))        # Fit data to visualizer\n","visualizer.show(outpath=\"../data/fidelity_elbow.pdf\")        # Finalize and render figure"]},{"cell_type":"code","execution_count":null,"id":"3db7fbd1","metadata":{"id":"3db7fbd1"},"outputs":[],"source":["# Check that embeddings_start_idx is correct!\n","embedding_start_idx = 13\n","df_embeddings_proj.iloc[:, embedding_start_idx:embedding_start_idx+768]"]},{"cell_type":"code","execution_count":null,"id":"898f796d","metadata":{"id":"898f796d"},"outputs":[],"source":["### STEP 9 - Finalize Clustering with Optimal k = X\n","np.random.seed(0)\n","# Optimal k from above figure in Elbow plot\n","k = 29\n","km = KMeans(n_clusters=k)\n","df_embeddings_proj['ClusterID'] = km.fit_predict(df_embeddings_proj.iloc[:, embedding_start_idx:embedding_start_idx+768])"]},{"cell_type":"code","execution_count":null,"id":"adce38de","metadata":{"id":"adce38de"},"outputs":[],"source":["# Check that you added a last column with ClusterID\n","df_embeddings_proj.head()"]},{"cell_type":"code","source":["# save the data\n","df_embeddings_proj.to_csv(r'../data/fidelity_cluster_data.csv')"],"metadata":{"id":"DS_2YkUl2GjW"},"id":"DS_2YkUl2GjW","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"dd1ba792","metadata":{"id":"dd1ba792"},"outputs":[],"source":["### STEP 10 - Visualize and Save\n","import numpy as np\n","import plotly.express as px\n","\n","df_embeddings_proj = df_embeddings_proj.sort_values(by=['ClusterID'])\n","df_embeddings_proj[\"ClusterID\"] = df_embeddings_proj[\"ClusterID\"].astype('category')\n","\n","\n","fig = px.scatter(\n","    df_embeddings_proj, x='tSNE1', y='tSNE2', \n","    color = 'ClusterID', hover_data = ['Title'],\n","    template='simple_white'\n",")\n","fig.update_traces(marker=dict(size=12,\n","                              line=dict(width=1,\n","                                        color='DarkSlateGrey')),\n","                  selector=dict(mode='markers'))\n","fig.show()\n","fig.write_html(\"../data/fidelity_clusters.html\")"]},{"cell_type":"code","execution_count":null,"id":"9ef88be3","metadata":{"id":"9ef88be3"},"outputs":[],"source":["# Derive and save wordclouds\n","# Wordclouds for Title and Abstracts\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","import re\n","import pandas as pd\n","\n","# identify a set of stopwords that need to be removed to improve wordcloud quality\n","stop_words = [\"virtual\", \"human\", \"agent\", \"ECA\", \"ECAs\", \"conversational\", \"humans\", \"agents\", \"user\"] + list(STOPWORDS)\n","\n","search_categories = ['Title', 'Abstract']\n","\n","for search_category in search_categories:\n","    for cluster_ID in range(k):\n","        temp_df = df_embeddings_proj.loc[df_embeddings_proj['ClusterID'] == cluster_ID]\n","        # Create and generate a word cloud image:\n","        all_text = ' '.join(temp_df[search_category])\n","        wordcloud = WordCloud(width=1600, height=800, stopwords = stop_words, background_color=\"white\").generate(all_text)\n","        wordcloud.to_file(r'../data/wordcloud/cluster_{}_{}.png'.format(cluster_ID, search_category))"]},{"cell_type":"code","source":["# Wordclouds for Authors\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","import re\n","import pandas as pd\n","\n","# Remove single letters and \"Anonymous\" as stopwords as well\n","stop_words = list(map(chr, range(97, 123))) + [\"Anonymous\"] + list(STOPWORDS)\n","\n","search_categories = ['Authors']\n","\n","for search_category in search_categories:\n","    for cluster_ID in range(k):\n","        temp_df = df_embeddings_proj.loc[df_embeddings_proj['ClusterID'] == cluster_ID]\n","        # Create and generate a word cloud image:\n","        all_text = ' '.join(temp_df[search_category])\n","        wordcloud = WordCloud(width=1600, height=800, stopwords = stop_words, background_color=\"white\").generate(all_text)\n","        wordcloud.to_file(r'../data/wordcloud/cluster_{}_{}.png'.format(cluster_ID, search_category))"],"metadata":{"id":"z5AcuhZ7rN4O"},"id":"z5AcuhZ7rN4O","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# OPTIONAL - Automated Topic Identification\n","!pip install pyate "],"metadata":{"id":"ql1Kos3r2mEj"},"id":"ql1Kos3r2mEj","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"894925c7","metadata":{"id":"894925c7"},"outputs":[],"source":["!pip install -U spacy"]},{"cell_type":"code","source":["!spacy download en_core_web_sm"],"metadata":{"id":"0R5yz3kX22ev"},"id":"0R5yz3kX22ev","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Automatically derive cluster topics\n","import spacy\n","from pyate.term_extraction_pipeline import TermExtractionPipeline\n","stop_words = list(STOPWORDS)\n","\n","search_categories = ['Abstract']\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","nlp.add_pipe(\"combo_basic\")\n","\n","for search_category in search_categories:\n","    for cluster_ID in range(k):\n","        print('--- ClusterID ' + str(cluster_ID) + ' ---')\n","        temp_df = df_embeddings_proj.loc[df_embeddings_proj['ClusterID'] == cluster_ID]\n","        all_text = '; '.join(temp_df[search_category])\n","        doc = nlp(all_text)\n","        print(doc._.combo_basic.sort_values(ascending=False).head(5))"],"metadata":{"id":"ju3oE4bT3Okd"},"id":"ju3oE4bT3Okd","execution_count":null,"outputs":[]}],"metadata":{"environment":{"name":"pytorch-gpu.1-9.m75","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m75"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"},"colab":{"name":"SemiAutomatedScopingReview.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}